{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KKjeIOfT3K-4",
        "colab_type": "text"
      },
      "source": [
        "Part 0:\n",
        "\n",
        "DONE\n",
        "\n",
        "Part 1:\n",
        "\n",
        "DONE\n",
        "\n",
        "Part 2:\n",
        "\n",
        "DONE (see lines 50-63)\n",
        "\n",
        "Part 3:\n",
        "\n",
        "DONE (using orthogonal initialization - see lines 93-113).  I found that uniform initializatoin caused NaN values boooo!\n",
        "![alt text](https://thleats-bucket.s3.us-east-2.amazonaws.com/CS/Lab3_v2.JPG)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Part 4:\n",
        "\n",
        "Quiz: DONE\n",
        "\n",
        "Using a Kernel size of 3×3 what should the settings of your 2d convolution be that results in the following mappings (first answer given to you)\n",
        "\n",
        "    (c=3, h=10, w=10) ⇒ (c=10, h=8, w=8) : (out_channels=10, kernel_size=(3, 3), padding=(0, 0))\n",
        "    (c=3, h=10, w=10) ⇒ (c=22, h=10, w=10) : **(out_channels=22, kernel_size=(3,3), padding=(1,1))**\n",
        "    (c=3, h=10, w=10) ⇒ (c=65, h=12, w=12) : **(out_channels=65, kernel_size=(3,3), padding=(2,2))**\n",
        "    (c=3, h=10, w=10) ⇒ (c=7, h=20, w=20) : **(out_channels=7, kernel_size=(3,3), padding=(6,6))**\n",
        "\n",
        "Using a Kernel size of 5×5:)\n",
        "\n",
        "    (c=3, h=10, w=10) ⇒ (c=10, h=8, w=8) : (out_channels=10, kernel_size=(5, 5), padding=(1, 1))\n",
        "    (c=3, h=10, w=10) ⇒ (c=100, h=10, w=10) : **(out_channels=100, kernel_size=(5,5), padding=(2,2))**\n",
        "    (c=3, h=10, w=10) ⇒ (c=23, h=12, w=12) : **(out_channels=23, kernel_size=(5,5), padding=(3,3))**\n",
        "    (c=3, h=10, w=10) ⇒ (c=5, h=24, w=24) : **(out_channels=5, kernel_size=(5,5), padding=(9,9))**\n",
        "\n",
        "Using Kernel size of 5×3:\n",
        "\n",
        "    (c=3, h=10, w=10) ⇒ (c=10, h=8, w=8) : **(out_channels=10, kernel_size=(5,3), padding=(1,0))**\n",
        "    (c=3, h=10, w=10) ⇒ (c=100, h=10, w=10) : **(out_channels=100, kernel_size=(5,3), padding=(2,1))**\n",
        "    (c=3, h=10, w=10) ⇒ (c=23, h=12, w=12) : **(out_channels=23, kernel_size=(5,3), padding=(3,2))**\n",
        "    (c=3, h=10, w=10) ⇒ (c=5, h=24, w=24) : **(out_channels=5, kernel_size=(5,3), padding=(9,8))**\n",
        "\n",
        "Determine the kernel that requires the smallest padding size to make the following mappings possible:\n",
        "\n",
        "    (c=3, h=10, w=10) ⇒ (c=10, h=9, w=7) :**(out_channels=10, kernel_size=(2,4), padding=(0,0))**\n",
        "    (c=3, h=10, w=10) ⇒ (c=22, h=10, w=10) : **(out_channels=22, kernel_size=(1,1), padding=(0,0))**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YL1pF2OiehKr",
        "colab_type": "code",
        "outputId": "f66c6e71-8e67-43ea-cdb4-72d2761070ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Fri Sep 13 12:09:11 2019\n",
        "\n",
        "@author: Nolan\n",
        "\"\"\"\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import transforms, utils, datasets\n",
        "from tqdm import tqdm\n",
        "import scipy\n",
        "from scipy import signal\n",
        "from torch.nn.parameter import Parameter\n",
        "import pdb\n",
        " \n",
        "assert torch.cuda.is_available() # You need to request a GPU from Runtime > Change Runtime Type\n",
        "\n",
        "def count_parameters(model):\n",
        "    total_param = 0\n",
        "    for name, param in model.named_parameters():\n",
        "        if param.requires_grad:\n",
        "            num_param = np.prod(param.size())\n",
        "            total_param += num_param\n",
        "    return total_param\n",
        "  \n",
        "\n",
        "class Conv2d(nn.Module):\n",
        "  def __init__(self, n_channels,out_channels,kernel_size,init_strategy='xav',stride=1,padding=0,dilation=1,groups=1,bias=True):\n",
        "    self.__dict__.update(locals())\n",
        "    super(Conv2d,self).__init__()\n",
        "    self.weight = Parameter(torch.Tensor(self.out_channels,\n",
        "                                         self.n_channels,\n",
        "                                         kernel_size[0],\n",
        "                                        kernel_size[1]))\n",
        "    #pdb.set_trace()\n",
        "    self.bias = Parameter(torch.Tensor(out_channels))\n",
        "    \n",
        "    #self.weight.data.uniform_(-1,1)\n",
        "    self.bias.data.uniform_(0,0)\n",
        "    \n",
        "    ##########################Initialization Strategy#######################\n",
        "    \n",
        "    #init_strategy = 'xav'\n",
        "    \n",
        "    if init_strategy == 'xav':\n",
        "      torch.nn.init.xavier_uniform_(self.weight)\n",
        "    elif init_strategy == 'orth':\n",
        "      M=np.random.random((self.out_channels,self.n_channels * kernel_size[0] * kernel_size[1])).astype(np.float32)\n",
        "      U,_, Vt= np.linalg.svd(M,full_matrices=False)\n",
        "      if len(M)>len(M[0]):\n",
        "        W=U.reshape((self.out_channels,self.n_channels,kernel_size[0],kernel_size[1]))\n",
        "      else:\n",
        "        W=Vt.reshape((self.out_channels,self.n_channels,kernel_size[0],kernel_size[1]))\n",
        "      self.weight.data=torch.from_numpy(W)\n",
        "    elif init_strategy == 'uni':\n",
        "      self.weight.data.uniform_(-1,1)\n",
        "    else:\n",
        "      torch.nn.init.xavier_uniform_(self.weight)\n",
        "    ########################################################################\n",
        "\n",
        "  def forward(self,x):\n",
        "    return F.conv2d(x,self.weight,self.bias,self.stride,\n",
        "                    self.padding,self.dilation,self.groups)\n",
        "\n",
        "class CE_me(nn.Module):\n",
        "  def __init__(self,weight=None,size_average=None,ignore_index=-100,reduce=None,reduction='mean'):\n",
        "    super(CE_me,self).__init__()\n",
        "    \n",
        "    \n",
        "  def forward(self,y_hat,y_truth):\n",
        "    right_side = torch.log(torch.sum(torch.exp(y_hat),dim=1))\n",
        "    n,classes = y_hat.size()\n",
        "    b=torch.zeros((n,classes))\n",
        "    b[np.arange(n),y_truth]=1\n",
        "    left_side = torch.sum(y_hat * b.cuda(),dim=1)\n",
        "    return torch.mean(-left_side + right_side)\n",
        "    \n",
        "\n",
        "########################Convolution Network Class###############################\n",
        "parameters=[]\n",
        "class ConvNetwork(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(ConvNetwork,self).__init__()\n",
        "    c=1\n",
        "    out = 10\n",
        "    \n",
        "    self.net = nn.Sequential(\n",
        "        Conv2d(c,10,(3,3),init_strategy='orth',padding=(1,1)),\n",
        "        nn.ReLU(),\n",
        "        \n",
        "        Conv2d(10,64,(3,3),init_strategy='orth',padding=(1,1)),        \n",
        "        nn.ReLU(),\n",
        "        \n",
        "        Conv2d(64,64,(3,3),init_strategy='orth',padding=(1,1)),        \n",
        "        nn.ReLU(),\n",
        "        \n",
        "        Conv2d(64,64,(5,5),init_strategy='orth',padding=(2,2)),        \n",
        "        nn.ReLU(),\n",
        "        \n",
        "        Conv2d(64,64,(5,5),init_strategy='orth',padding=(2,2)),        \n",
        "        nn.ReLU(),\n",
        "        \n",
        "        Conv2d(64,64,(7,7),init_strategy='orth',padding=(3,3)),        \n",
        "        nn.ReLU(),\n",
        "        \n",
        "\n",
        "        \n",
        "        Conv2d(64,64,(9,9),init_strategy='orth',padding=(4,4)),        \n",
        "        nn.ReLU(),\n",
        "              \n",
        "        \n",
        "        Conv2d(64,10,(28,28), padding = (0,0)),\n",
        "        nn.ReLU(),\n",
        "        \n",
        "        \n",
        "        \n",
        "        Conv2d(10,out,(1,1), padding=(0,0)),\n",
        "     \n",
        "        \n",
        "    )\n",
        "    \n",
        "  def forward(self,x):\n",
        "    return self.net(x).squeeze(2).squeeze(2)\n",
        "########################################################################    \n",
        "        \n",
        "class FashionMNISTProcessedDataset(Dataset):\n",
        "  def __init__(self,root,train=True):\n",
        "    self.data=datasets.FashionMNIST(root,train=train,transform=transforms.ToTensor(),download=True)   \n",
        "  def __getitem__(self,i):\n",
        "    x,y=self.data[i]\n",
        "    return x,y\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "    \n",
        "train_dataset=FashionMNISTProcessedDataset('/tmp/fashionmnist',train=True)\n",
        "val_dataset=FashionMNISTProcessedDataset('/tmp/fashionmnist',train=False)\n",
        "\n",
        "model = ConvNetwork()\n",
        "model=model.cuda()\n",
        "#model = LinearNetwork(train_dataset)\n",
        "\n",
        "objective = CE_me()#replace this\n",
        "\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(),lr=1e-4)\n",
        "train_loader = DataLoader(train_dataset,\n",
        "                         batch_size=42,\n",
        "                         pin_memory=True)\n",
        "valid_load = DataLoader(val_dataset,batch_size=round(len(val_dataset)/len(train_loader)),pin_memory=True)\n",
        "\n",
        "\n",
        "losses=[]\n",
        "losses_valid=[]\n",
        "loss_mean=[]\n",
        "acc_vec=[]\n",
        "acc_epoch=[]\n",
        "epochs=10\n",
        "accuracy_v=0\n",
        "accuracy_t=0\n",
        "acc_vec_t=[]\n",
        "for epoch in range(epochs):\n",
        "  \n",
        "  loop = tqdm(total=len(train_loader), position = 0)\n",
        "  \n",
        "  for loader in zip(train_loader,valid_load):\n",
        "\n",
        "    x,x_valid = [thing[0] for thing in loader]\n",
        "    y_truth,y_valid = [thing[1] for thing in loader]\n",
        "\n",
        "    x,y_truth = x.cuda(async=True),y_truth.cuda(async=True)\n",
        "    \n",
        "    #x_valid,y_truth_valid = x_valid.cuda(async=True),y_valid.cuda(async=True)\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    \n",
        "    \n",
        "    #with torch.no_grad():\n",
        "     # y_nohat=model(x_valid)\n",
        "      #loss_valid = objective(y_nohat,y_truth_valid)\n",
        "      \n",
        "    y_hat=model(x)\n",
        "    \n",
        "    pre_acc_t = torch.argmax(y_hat,1)-y_truth\n",
        "    accuracy_t = (y_truth.size(0)-pre_acc_t.nonzero().size(0))/pre_acc_t.size(0)\n",
        "    pdb.set_trace()\n",
        "    \n",
        "    loss = objective(y_hat, y_truth)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    losses.append(loss)\n",
        "    #losses_valid.append(loss_valid)\n",
        " \n",
        "    loop.set_description('loss:{:.4f}'.format(loss.item()))    \n",
        "    loop.update(1)\n",
        "    acc_vec_t.append(accuracy_t)\n",
        "  \n",
        "  accuracy_v=0\n",
        "  for x_valid,y_truth_valid in valid_load:\n",
        "    x_valid,y_truth_valid = x_valid.cuda(async=True),y_truth_valid.cuda(async=True)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "      y_nohat=model(x_valid)\n",
        "      pre_acc = torch.argmax(y_nohat,1)-y_truth_valid\n",
        "      accuracy_v = (y_truth_valid.size(0)-pre_acc.nonzero().size(0))/pre_acc.size(0)\n",
        "      \n",
        "      #pdb.set_trace()\n",
        "      loss_valid = (objective(y_nohat,y_truth_valid))\n",
        "      losses_valid.append(loss_valid.item())\n",
        "    loss_mean.append(np.mean(losses_valid))\n",
        "    acc_vec.append(accuracy_v)\n",
        "  \n",
        "  loop.close()\n",
        "print(len(losses))\n",
        "\n",
        "iterations=range(0,len(losses),1)\n",
        "valid_iterations=range(0,len(loss_mean),1)\n",
        "#losses_valid=signal.savgol_filter(losses_valid,51,2)\n",
        "\n",
        "losses=signal.savgol_filter(losses,21,2)\n",
        "acc_vec=signal.savgol_filter(acc_vec,21,2)\n",
        "acc_vec_t=signal.savgol_filter(acc_vec_t,21,2)\n",
        "\n",
        "fix, ax = plt.subplots()\n",
        "\n",
        "loss_v=ax.plot(iterations,loss_mean,label='Validation Loss')\n",
        "loss_t=ax.plot(iterations,losses,label='Training Loss')\n",
        "acc=ax.plot(iterations,acc_vec,label='Accuracy Validation')\n",
        "acc_t=ax.plot(iterations,acc_vec_t,label='Accuracy Training')\n",
        "\n",
        "\n",
        "\n",
        "ax.legend()\n",
        "\n",
        "\n",
        "ax.set(xlabel='iterations', ylabel='loss & accuracy',\n",
        "       title='Lab2 Plot')\n",
        "ax.grid()\n",
        "\n",
        "\n",
        "plt.show()\n",
        "\n",
        "\n",
        "print('Total parameters is: ' + str(count_parameters(model)))\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "with open('/home/ubuntu/foo.txt', 'w') as f:\n",
        "  out=torch.save(model.state_dict(),'/content/drive/My Drive/foo.txt')\n",
        "  \n",
        "files.download('foo.txt')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/1429 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "> <ipython-input-1-39bfa4f0c7d0>(192)<module>()\n",
            "-> loss = objective(y_hat, y_truth)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FEK4vBriShib",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "with open('/content/drive/My Drive/foo.txt', 'w') as f:\n",
        "  out=torch.save(model.state_dict(),'/content/drive/My Drive/foo.txt')\n",
        "  \n",
        "files.download('foo.txt')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JPUko7Ftfrwc",
        "colab_type": "text"
      },
      "source": [
        "\n"
      ]
    }
  ]
}